{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:27.523845Z",
     "start_time": "2018-02-21T14:35:25.088889Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape, BatchNormalization, Dropout\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import utils\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:27.531791Z",
     "start_time": "2018-02-21T14:35:27.523845Z"
    }
   },
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"..\\\\fma_small\"\n",
    "META_DIR = \"..\\\\fma_metadata\"\n",
    "SUBSET = 'small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:27.667781Z",
     "start_time": "2018-02-21T14:35:27.655772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load metadata to memory\n",
    "def load_meta_data(): \n",
    "    tracks_all   = utils.load(META_DIR + '\\\\tracks.csv')\n",
    "    features_all = utils.load(META_DIR + '\\\\features.csv')\n",
    "    echonest_all = utils.load(META_DIR + '\\\\echonest.csv')\n",
    "\n",
    "    #genres = utils.load(META_DIR + 'genres.csv')\n",
    "\n",
    "    np.testing.assert_array_equal(features_all.index, tracks_all.index)\n",
    "    assert echonest_all.index.isin(tracks_all.index).all()\n",
    "    \n",
    "    \n",
    "    return tracks_all, features_all, echonest_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:28.155765Z",
     "start_time": "2018-02-21T14:35:28.147765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose Subset\n",
    "def choose_small_subset(tracks_all, features_all, echonest_all):\n",
    "    subset = tracks_all.index[tracks_all['set', 'subset'] <= 'small']\n",
    "\n",
    "    assert subset.isin(tracks_all.index).all()\n",
    "    assert subset.isin(features_all.index).all()\n",
    "    \n",
    "    tracks = tracks_all.loc[subset]\n",
    "    features = features_all.loc[subset]\n",
    "\n",
    "    return tracks, features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.113433Z",
     "start_time": "2018-02-21T14:35:28.825309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeffrey\\Desktop\\172B\\Amadeus\\fma_code\\utils.py:214: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  'category', categories=SUBSETS, ordered=True)\n"
     ]
    }
   ],
   "source": [
    "tracks_all, features_all, echonest_all = load_meta_data()\n",
    "tracks, features =  choose_small_subset(tracks_all, features_all, echonest_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.121372Z",
     "start_time": "2018-02-21T14:35:54.113433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 52), (8000, 518))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.shape, features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Val Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.185343Z",
     "start_time": "2018-02-21T14:35:54.121372Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples\n",
      "800 validation examples\n",
      "800 testing examples\n"
     ]
    }
   ],
   "source": [
    "# Splitting into Train, Validation, Test\n",
    "train_index = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val_index   = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test_index  = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "\n",
    "print('{} training examples'.format(len(train_index)))\n",
    "print('{} validation examples'.format(len(val_index)))\n",
    "print('{} testing examples'.format(len(test_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.201375Z",
     "start_time": "2018-02-21T14:35:54.185343Z"
    }
   },
   "outputs": [],
   "source": [
    "X = features.values\n",
    "Y = tracks['track']['genre_top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.273342Z",
     "start_time": "2018-02-21T14:35:54.201375Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain = features.loc[train_index].values\n",
    "Xval  = features.loc[val_index].values\n",
    "Xtest  = features.loc[test_index].values\n",
    "\n",
    "Ytrain = tracks.loc[train_index]['track']['genre_top'].values\n",
    "Yval = tracks.loc[val_index]['track']['genre_top'].values\n",
    "Ytest = tracks.loc[test_index]['track']['genre_top'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.285345Z",
     "start_time": "2018-02-21T14:35:54.277346Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = list(set(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Baseline (Works Well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.393346Z",
     "start_time": "2018-02-21T14:35:54.285345Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain = features.loc[train_index].values\n",
    "Xval  = features.loc[val_index].values\n",
    "Xtest  = features.loc[test_index].values\n",
    "\n",
    "Ytrain = tracks.loc[train_index]['track']['genre_top']\n",
    "Yval = tracks.loc[val_index]['track']['genre_top']\n",
    "Ytest = tracks.loc[test_index]['track']['genre_top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:54.401342Z",
     "start_time": "2018-02-21T14:35:54.393346Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(verbose=2, max_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:23:01.416042Z",
     "start_time": "2018-02-21T14:22:35.131710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8ecde870a440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logreg.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:23:01.444044Z",
     "start_time": "2018-02-21T14:23:01.416042Z"
    }
   },
   "outputs": [],
   "source": [
    "YtrainHat = logreg.predict(Xtrain)\n",
    "np.mean(Ytrain == YtrainHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:23:01.456053Z",
     "start_time": "2018-02-21T14:23:01.444044Z"
    }
   },
   "outputs": [],
   "source": [
    "YtestHat = logreg.predict(Xtest)\n",
    "np.mean(Ytest == YtestHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:23:01.480014Z",
     "start_time": "2018-02-21T14:23:01.456053Z"
    }
   },
   "outputs": [],
   "source": [
    "YvalHat = logreg.predict(Xval)\n",
    "np.mean(Yval == YvalHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:23:02.056017Z",
     "start_time": "2018-02-21T14:23:01.480014Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(Ytest, YtestHat)\n",
    "plot_confusion_matrix(cnf_matrix, classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model No Audio (broken model predicts all same genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:26:08.720635Z",
     "start_time": "2018-02-21T14:26:08.716634Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = 518\n",
    "genres = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:26:09.036675Z",
     "start_time": "2018-02-21T14:26:08.996637Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelBinarizer = LabelBinarizer()\n",
    "ohTrain = labelBinarizer.fit_transform(X=Ytrain)\n",
    "ohVal  = labelBinarizer.fit_transform(X=Yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:32:23.971748Z",
     "start_time": "2018-02-21T14:32:23.963744Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_env_and_tfboard(model_name = \"Model\"):\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "    TFboard = keras.callbacks.TensorBoard(log_dir='./logs/' + model_name + '_' + now.strftime(\"%Y%m%d-%H%M%S\")  +'/', histogram_freq = 0)\n",
    "    return TFboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:27:42.911088Z",
     "start_time": "2018-02-21T14:27:42.779116Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "TFBoard = init_env_and_tfboard()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(features,), \n",
    "          kernel_initializer='random_uniform', bias_initializer='zeros'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(128),\n",
    "    Dropout(0.8),\n",
    "    Activation('relu'),\n",
    "    Dense(genres),\n",
    "    Activation('softmax'),\n",
    "])    \n",
    "    \n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer, loss='mean_squared_error', metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T11:25:15.625498Z",
     "start_time": "2018-02-21T11:25:15.617496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106574 entries, 2 to 155320\n",
      "Columns: 518 entries, (chroma_cens, kurtosis, 01) to (zcr, std, 01)\n",
      "dtypes: float64(518)\n",
      "memory usage: 427.0 MB\n"
     ]
    }
   ],
   "source": [
    "features_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:35:15.768721Z",
     "start_time": "2018-02-21T14:35:15.720715Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"callbacks\": [TFBoard],\n",
    "        \"validation_data\": (Xval, ohVal)\n",
    "}\n",
    "history = model.fit(x = Xtrain, y = ohTrain , epochs=100, **params, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T13:06:10.280590Z",
     "start_time": "2018-02-20T13:06:09.891186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronic', 'Electronic', 'Electronic', ..., 'Electronic',\n",
       "       'Electronic', 'Electronic'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelBinarizer.inverse_transform(model.predict(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T12:59:23.879991Z",
     "start_time": "2018-02-20T12:59:23.871959Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Model Using Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:42:48.191075Z",
     "start_time": "2018-02-21T14:42:48.171048Z"
    }
   },
   "outputs": [],
   "source": [
    "trainIDs = tracks.loc[train_index][\"track\"].index.values\n",
    "valIDs  = tracks.loc[val_index][\"track\"].index.values\n",
    "testIDs  = tracks.loc[test_index][\"track\"].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:42:55.007607Z",
     "start_time": "2018-02-21T14:42:54.983575Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_onehot = MultiLabelBinarizer().fit_transform(tracks['track', 'genre_top'])\n",
    "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T14:42:55.463577Z",
     "start_time": "2018-02-21T14:42:55.155583Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8a607a5613c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sanitation Test, Just making sure it works\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFfmpegLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_audio_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUDIO_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSampleLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_sample_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUDIO_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFfmpegLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mSampleLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainIDs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\172B\\Amadeus\\fma_code\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmd_prefix\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\Jeffrey\\\\Anaconda2\\\\envs\\\\samadeus\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\172B\\Amadeus\\fma_code\\utils.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(self, filepath, cmd_prefix)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;31m# 30s at 44.1 kHz ~= 1.3e6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEVNULL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int16\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\amadeus\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\amadeus\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    674\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\amadeus\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# Sanitation Test, Just making sure it works\n",
    "utils.FfmpegLoader().load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, utils.FfmpegLoader())\n",
    "SampleLoader(trainIDs, batch_size=2).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:20:45.687946Z",
     "start_time": "2018-02-21T15:20:45.348718Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing librosa\n",
    "librosaLoader = utils.LibrosaLoader()\n",
    "t2 = librosaLoader.load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "t5 = librosaLoader.load(utils.get_audio_path(AUDIO_DIR, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-10T18:39:30.798238Z",
     "start_time": "2018-02-10T18:39:30.792190Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-10T16:44:01.769571Z",
     "start_time": "2018-02-10T16:44:01.761548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_fully_connected(loader, labels_onehot):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(units=1000, input_shape=loader.shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(units=100))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(units=labels_onehot.shape[1]))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:23:40.748531Z",
     "start_time": "2018-02-21T15:23:40.740497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality: (1321967,)\n"
     ]
    }
   ],
   "source": [
    "loader = utils.LibrosaLoader()\n",
    "librosaBatchLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "print('Dimensionality: {}'.format(loader.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-10T17:50:02.149423Z",
     "start_time": "2018-02-10T17:48:43.886742Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = basic_fully_connected(loader, labels_onehot)\n",
    "model.fit_generator(SampleLoader(train, batch_size=64), train.size/100, epochs=2, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=64), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=64), test.size, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:25:23.050919Z",
     "start_time": "2018-02-21T15:25:23.038919Z"
    }
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"../test_samples/2test.p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:24:37.413081Z",
     "start_time": "2018-02-21T15:24:37.405075Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../test_samples/2test.p\",'rb') as infile:\n",
    "    df = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T15:26:01.880042Z",
     "start_time": "2018-02-21T15:26:01.872029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330780,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"raw_songs\"].values[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN using the 128x128 patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEC_DIR = \"..\\\\spectrogram\\\\\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GRU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "def cnn_model(input_shape=(105,105,3), output = 8):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.summary()\n",
    "#     model.add(Flatten())\n",
    "    model.add(Reshape((11, 11*64)))\n",
    "    model.add(GRU(32, return_sequences=True, name='gru1'))\n",
    "    model.add(GRU(32, return_sequences=False, name='gru2'))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',  \n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 8 classes.\n",
      "Found 8000 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#SPEC_DIR WAS CHANGED BECAUSE I DON\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        SPEC_DIR,  \n",
    "        target_size=(105, 105),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        SPEC_DIR,\n",
    "        target_size=(105, 105),\n",
    "        batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 103, 103, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 103, 103, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 51, 51, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 49, 49, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 11, 704)           0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 11, 32)            70752     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 108,264\n",
      "Trainable params: 108,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 103, 103, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 103, 103, 32)      0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TFBoard = init_env_and_tfboard(\"cnn\")\n",
    "model = cnn_model(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('cnn_try_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 128s - loss: 2.0721 - acc: 0.1442 - val_loss: 2.0296 - val_acc: 0.2000\n",
      "Epoch 2/50\n",
      " - 135s - loss: 1.9872 - acc: 0.2235 - val_loss: 1.8117 - val_acc: 0.3513\n",
      "Epoch 3/50\n",
      " - 138s - loss: 1.8216 - acc: 0.3247 - val_loss: 1.9670 - val_acc: 0.3075\n",
      "Epoch 4/50\n",
      " - 144s - loss: 1.6893 - acc: 0.3927 - val_loss: 1.4674 - val_acc: 0.5125\n",
      "Epoch 5/50\n",
      " - 140s - loss: 1.5868 - acc: 0.4405 - val_loss: 1.3805 - val_acc: 0.5337\n",
      "Epoch 6/50\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#         \"callbacks\": [TFBoard],\n",
    "        \"verbose\": 2\n",
    "}\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch = 10000 / batch_size, \n",
    "                    epochs = 50,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=800 // batch_size,\n",
    "                    **params)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('cnn_try_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
